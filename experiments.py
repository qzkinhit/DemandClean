# 1. å®éªŒé…ç½®å’Œæ•°æ®ç”Ÿæˆå‡½æ•°
from DQN_extract import *
import matplotlib.patches as mpatches
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.patheffects as path_effects

def setup_experiment(error_rates, models, task_type, n_samples, n_features,
                     missing_ratio, outlier_ratio, noise_ratio):
    """
    è®¾ç½®å®éªŒé…ç½®å¹¶è¿”å›åˆå§‹åŒ–çš„æ•°æ®ç»“æ„
    """
    # å­˜å‚¨å®éªŒç»“æœ
    results = {model: {er: {} for er in error_rates} for model in models}
    action_dist = {model: {er: {} for er in error_rates} for model in models}
    tolerances = {model: [] for model in models}

    return results, action_dist, tolerances


# 2. ç‰¹å¾é‡è¦æ€§è®¡ç®—å‡½æ•°
def calculate_feature_importance(df, task_type):
    """ä½¿ç”¨éšæœºæ£®æ—è®¡ç®—ç‰¹å¾é‡è¦æ€§"""
    X = df.drop('target', axis=1)
    y = df['target']

    if task_type == 'classification':
        model = RandomForestClassifier(n_estimators=50, random_state=42)
    else:
        model = RandomForestRegressor(n_estimators=50, random_state=42)

    model.fit(X, y)
    importances = model.feature_importances_

    return {feature: importance for feature, importance in zip(X.columns, importances)}


# 3. è¿è¡Œå•ä¸ªé”™è¯¯ç‡çš„å®éªŒ
def run_single_error_rate_experiment(error_rate, models, task_type, n_samples, n_features,
                                     missing_ratio, outlier_ratio, noise_ratio, results,
                                     action_dist, tolerances):
    """è¿è¡Œå•ä¸ªé”™è¯¯ç‡çš„å®éªŒå¹¶æ›´æ–°ç»“æœ"""
    print(f"Running experiment with error rate: {error_rate}")

    # è®­ç»ƒé˜¶æ®µï¼šç”Ÿæˆå¹²å‡€æ•°æ®é›†å’Œè®¡ç®—ç‰¹å¾é‡è¦æ€§
    train_clean_df = generate_clean_data(task_type=task_type, n_samples=n_samples, n_features=n_features)
    feature_importance = calculate_feature_importance(train_clean_df, task_type)
    print(f"Feature importance: {feature_importance}")

    # åˆ›å»ºè®­ç»ƒç”¨é”™è¯¯æ³¨å…¥å™¨
    train_injector = ErrorInjector(train_clean_df)

    # è®¡ç®—æ¯ç§é”™è¯¯ç±»å‹çš„é”™è¯¯ç‡
    missing_err_rate = error_rate * missing_ratio
    outlier_err_rate = error_rate * outlier_ratio
    noise_err_rate = error_rate * noise_ratio

    # æ³¨å…¥è®­ç»ƒæ•°æ®é”™è¯¯ï¼ˆæŒ‰ç‰¹å¾é‡è¦æ€§ï¼‰
    train_injector.inject_missing_values(error_rate=missing_err_rate, feature_importance=feature_importance)
    train_injector.inject_outliers(error_rate=outlier_err_rate, feature_importance=feature_importance)
    train_injector.inject_noise(error_rate=noise_err_rate, feature_importance=feature_importance)

    # è·å–è®­ç»ƒç”¨é”™è¯¯æ•°æ®
    train_df_with_errors = train_injector.df

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train_full = train_clean_df.drop('target', axis=1)
    y_train_full = train_clean_df['target']
    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)

    # å¯¹æ¯ä¸ªæ¨¡å‹è¿è¡Œå®éªŒ
    for model_name in models:
        print(f"  Testing model: {model_name}")
        # åˆå§‹åŒ–MLæ¨¡å‹
        ml_model = initialize_ml_model(task_type, model_name)

        # åˆ›å»ºè®­ç»ƒç¯å¢ƒå’Œè¯„ä¼°å™¨
        train_env = DataCleaningEnv(train_df_with_errors.copy(), ml_model, train_injector.error_locations,
                                    task_type=task_type, model_type=model_name)

        # è®­ç»ƒRLä»£ç†
        agent,_ = train_rl_agent(train_env, train_injector.error_locations)

        # æµ‹è¯•é˜¶æ®µï¼šç”Ÿæˆæ–°çš„å¹²å‡€æµ‹è¯•æ•°æ®å’Œæ³¨å…¥é”™è¯¯
        test_clean_df, test_df_with_errors, test_injector = generate_test_data(
            task_type, n_samples, n_features, missing_err_rate, outlier_err_rate,
            noise_err_rate, feature_importance)

        # å‡†å¤‡æµ‹è¯•è¯„ä¼°å™¨å’Œç¯å¢ƒ
        test_evaluator, test_env = setup_test_environment(
            test_clean_df, test_df_with_errors, test_injector, ml_model,
            task_type, model_name)

        # è¯„ä¼°ä¸åŒç­–ç•¥
        strat_perf = evaluate_strategies(
            task_type, test_df_with_errors,
            test_injector.error_locations, test_evaluator, test_env, agent)

        # è®°å½•ç»“æœ
        update_results(results, action_dist, tolerances, model_name, error_rate,
                       task_type, strat_perf, test_env, test_injector, agent)

    return results, action_dist, tolerances


# 4. æ¨¡å‹åˆå§‹åŒ–å‡½æ•°
def initialize_ml_model(task_type, model_name):
    """åˆå§‹åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹"""
    if task_type == 'classification':
        if model_name == 'random_forest':
            return RandomForestClassifier(n_estimators=10, random_state=42)
        elif model_name == 'svm':
            return SVC(probability=True, random_state=42)
        else:
            return LogisticRegression(random_state=42)
    else:
        if model_name == 'random_forest':
            return RandomForestRegressor(n_estimators=10, random_state=42)
        elif model_name == 'svm':
            return SVR()
        else:
            return LinearRegression()


# 5. RLä»£ç†è®­ç»ƒå‡½æ•°
def train_rl_agent(train_env, error_locations, n_episodes=80, model_name="default_agent",
                   reload_model=False, models_dir="saved_models", batch_size=32,
                   save_interval=None, learning_rate=0.001, exploration_rate=None, verbose=True):
    """
    è®­ç»ƒRLä»£ç†ï¼Œæ”¯æŒè¿›åº¦æ˜¾ç¤ºã€æ¨¡å‹ä¿å­˜å’ŒåŠ è½½

    å‚æ•°:
        train_env: è®­ç»ƒç¯å¢ƒ
        error_locations: é”™è¯¯ä½ç½®å­—å…¸
        n_episodes: è®­ç»ƒè½®æ¬¡
        model_name: æ¨¡å‹åç§°ï¼Œç”¨äºä¿å­˜å’ŒåŠ è½½
        reload_model: æ˜¯å¦åŠ è½½å·²æœ‰æ¨¡å‹
        models_dir: æ¨¡å‹ä¿å­˜ç›®å½•
        batch_size: ç»éªŒå›æ”¾æ‰¹é‡å¤§å°
        save_interval: æ¨¡å‹ä¿å­˜é—´éš”ï¼ˆè½®æ¬¡ï¼‰ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼
        learning_rate: å­¦ä¹ ç‡ï¼Œå¦‚æœåŠ è½½æ¨¡å‹åˆ™å¿½ç•¥
        exploration_rate: æ¢ç´¢ç‡ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨DQNAgenté»˜è®¤å€¼
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†è¿›åº¦

    è¿”å›:
        è®­ç»ƒå¥½çš„RLä»£ç†
    """
    # ç¡®ä¿æ¨¡å‹ç›®å½•å­˜åœ¨
    if not os.path.exists(models_dir):
        os.makedirs(models_dir)

    # æ„å»ºå®Œæ•´çš„æ¨¡å‹è·¯å¾„
    model_path = os.path.join(models_dir, f"{model_name}.h5")

    # è®¡ç®—ä¿å­˜é—´éš”
    if save_interval is None:
        save_interval = max(1, n_episodes // 5)  # é»˜è®¤åœ¨20%ã€40%ã€60%ã€80%å’Œ100%ä¿å­˜

    # åˆå§‹åŒ–ä»£ç†
    agent = DQNAgent(state_size=5, action_size=3)

    # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ¢ç´¢ç‡
    if exploration_rate is not None:
        agent.epsilon = exploration_rate

    # å¦‚æœè®¾ç½®äº†åŠ è½½æ¨¡å‹ä¸”æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™åŠ è½½
    loaded_model = False
    if reload_model and os.path.exists(model_path):
        try:
            agent.model = tf.keras.models.load_model(model_path, compile=False)
            agent.model.compile(loss='mse', optimizer=Adam(learning_rate=learning_rate))
            loaded_model = True
            if verbose:
                print(f"Loaded model from {model_path}")
        except Exception as e:
            print(f"Error loading model: {e}")
            print("Training new model instead.")

    # å¦‚æœæ²¡æœ‰åŠ è½½æ¨¡å‹ï¼Œæ˜¾ç¤ºä½¿ç”¨çš„å­¦ä¹ ç‡
    if not loaded_model and verbose:
        print(f"Training new model with learning rate: {learning_rate}")

    # åˆ›å»ºè®­ç»ƒæ—¥å¿—
    training_log = {
        'episode_rewards': [],
        'episode_steps': [],
        'model_path': model_path,
        'loaded_model': loaded_model
    }

    # ä½¿ç”¨tqdmæ˜¾ç¤ºè®­ç»ƒè¿›åº¦
    episodes_range = tqdm(range(n_episodes), desc="Training episodes") if verbose else range(n_episodes)

    for e in episodes_range:
        state = train_env.reset()
        steps = 0
        total_reward = 0

        # å†…éƒ¨æ­¥éª¤è¿›åº¦æ¡
        step_iterator = range(len(error_locations))
        if verbose and n_episodes <= 10:  # åªæœ‰å½“è½®æ¬¡è¾ƒå°‘æ—¶æ‰æ˜¾ç¤ºæ­¥éª¤è¿›åº¦æ¡
            step_iterator = tqdm(step_iterator, desc=f"Episode {e + 1} steps", leave=False)

        for _ in step_iterator:
            action = agent.act(state)
            next_state, reward, done, _ = train_env.step(action)
            agent.remember(state, action, reward, next_state, done)

            total_reward += reward
            state = next_state
            steps += 1

            if done:
                break

        # è®°å½•æœ¬è½®çš„æ­¥æ•°å’Œå¥–åŠ±
        training_log['episode_rewards'].append(total_reward)
        training_log['episode_steps'].append(steps)

        # åªæœ‰å½“ç»éªŒæ± è¶³å¤Ÿå¤§æ—¶æ‰è¿›è¡Œå›æ”¾
        if len(agent.memory) > batch_size:
            agent.replay(batch_size=batch_size)

        # åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾ç¤ºä¿¡æ¯
        if verbose and (e + 1) % max(1, n_episodes // 10) == 0:
            avg_reward = np.mean(training_log['episode_rewards'][-10:])
            avg_steps = np.mean(training_log['episode_steps'][-10:])
            print(
                f"Episode {e + 1}/{n_episodes} - Avg Reward: {avg_reward:.2f}, Avg Steps: {avg_steps:.2f}, Epsilon: {agent.epsilon:.4f}")

        # å®šæœŸä¿å­˜æ¨¡å‹
        if (e + 1) % save_interval == 0 or e == n_episodes - 1:
            agent.model.save(model_path)
            if verbose:
                print(f"Model saved to {model_path} after episode {e + 1}/{n_episodes}")

    # å®Œæˆè®­ç»ƒåä¿å­˜æ¨¡å‹
    agent.model.save(model_path)
    if verbose:
        print(f"Training completed. Final model saved to {model_path}")

    return agent, training_log


# 6. ç”Ÿæˆæµ‹è¯•æ•°æ®å‡½æ•°
def generate_test_data(task_type, n_samples, n_features, missing_err_rate,
                       outlier_err_rate, noise_err_rate, feature_importance):
    """ç”Ÿæˆæµ‹è¯•æ•°æ®é›†å¹¶æ³¨å…¥é”™è¯¯"""
    test_clean_df = generate_clean_data(task_type=task_type, n_samples=n_samples, n_features=n_features)

    # åˆ›å»ºæµ‹è¯•ç”¨é”™è¯¯æ³¨å…¥å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„ç‰¹å¾é‡è¦æ€§ï¼‰
    test_injector = ErrorInjector(test_clean_df)

    # æ³¨å…¥æµ‹è¯•æ•°æ®é”™è¯¯
    test_injector.inject_missing_values(error_rate=missing_err_rate)
    test_injector.inject_outliers(error_rate=outlier_err_rate)
    test_injector.inject_noise(error_rate=noise_err_rate)

    # è·å–æµ‹è¯•ç”¨é”™è¯¯æ•°æ®
    test_df_with_errors = test_injector.df

    return test_clean_df, test_df_with_errors, test_injector


# 7. è®¾ç½®æµ‹è¯•ç¯å¢ƒå‡½æ•°
def setup_test_environment(test_clean_df, test_df_with_errors, test_injector,
                           ml_model, task_type, model_name):
    """è®¾ç½®æµ‹è¯•è¯„ä¼°å™¨å’Œç¯å¢ƒ"""
    # å‡†å¤‡æµ‹è¯•è¯„ä¼°å™¨
    X_test_full = test_clean_df.drop('target', axis=1)
    y_test_full = test_clean_df['target']
    X_train_test, X_val_test, y_train_test, y_val_test = train_test_split(
        X_test_full, y_test_full, test_size=0.3, random_state=42)

    test_evaluator = ModelEvaluator(
        X_train_test, y_train_test, X_val_test, y_val_test,
        task_type=task_type, model_type=model_name)

    # åˆ›å»ºæµ‹è¯•ç¯å¢ƒ
    test_env = DataCleaningEnv(
        test_df_with_errors.copy(), ml_model, test_injector.error_locations,
        task_type=task_type, model_type=model_name)

    return test_evaluator, test_env


# 8. æ›´æ–°ç»“æœå‡½æ•°
def update_results(results, action_dist, tolerances, model_name, error_rate,
                   task_type, strat_perf, test_env, test_injector, agent):
    """æ›´æ–°å®éªŒç»“æœæ•°æ®ç»“æ„"""
    # è®°å½•æ€§èƒ½æŒ‡æ ‡
    metric_key = 'accuracy' if task_type == 'classification' else 'r2_score'

    results[model_name][error_rate] = {
        'do_nothing': strat_perf['do_nothing'][metric_key],
        'delete_all': strat_perf['delete_all'][metric_key],
        'repair_all': strat_perf['repair_all'][metric_key],
        'rl_optimal': strat_perf['RL_optimal'][metric_key]
    }

    # è®¡ç®—å®¹å¿åº¦ (RLç­–ç•¥æå‡/ç†æƒ³æå‡æ¯”ä¾‹)
    rl_gain = results[model_name][error_rate]['rl_optimal'] - results[model_name][error_rate]['do_nothing']
    ideal_gain = results[model_name][error_rate]['repair_all'] - results[model_name][error_rate]['do_nothing']
    tolerance = rl_gain / ideal_gain if ideal_gain > 0 else 1.0
    tolerances[model_name].append(tolerance)

    # æ”¶é›†åŠ¨ä½œåˆ†å¸ƒ
    test_env.df = test_env.df.copy()
    test_env.current_error_idx = 0
    actions = []

    state = test_env.reset()
    for _ in range(len(test_injector.error_locations)):
        action = agent.act(state)
        actions.append(action)
        next_state, _, done, _ = test_env.step(action)
        state = next_state
        if done: break

    # è®¡ç®—åŠ¨ä½œæ¯”ä¾‹
    actions = np.array(actions)
    action_dist[model_name][error_rate] = {
        'no_action': np.sum(actions == 0) / len(actions),
        'repair': np.sum(actions == 1) / len(actions),
        'delete': np.sum(actions == 2) / len(actions)
    }

    return results, action_dist, tolerances


# 9. ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒå›¾å‡½æ•°
def plot_action_distribution(action_dist, models, error_rates, enhanced=True):
    """ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒå¯¹æ¯”å›¾"""
    fig, ax = plt.subplots(figsize=(7, 4.5))
    bar_width = 0.065
    index = np.arange(3)  # 3ç§åŠ¨ä½œ
    action_names = ['No Action', 'Repair', 'Delete']

    # é¢œè‰²æ˜ å°„ - ä½¿ç”¨å¯¹æ¯”åº¦æ›´é«˜çš„é¢œè‰²
    if enhanced:
        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # æ›´é²œæ˜çš„é¢œè‰²
    else:
        colors = plt.cm.tab10(np.linspace(0, 1, len(models)))

    hatches = ['', '///', 'xxx', '...', '+++']  # ç”¨äºåŒºåˆ†é”™è¯¯ç‡

    # ç»˜åˆ¶æ¡å½¢å›¾
    for m_idx, model in enumerate(models):
        for e_idx, er in enumerate(error_rates[::1]):  # é€‰æ‹©éƒ¨åˆ†é”™è¯¯ç‡ä»¥é¿å…è¿‡åº¦æ‹¥æŒ¤
            values = [action_dist[model][er]['no_action'],
                      action_dist[model][er]['repair'],
                      action_dist[model][er]['delete']]

            # è®¡ç®—æ¡å½¢ä½ç½®
            offset = (m_idx * len(error_rates[::1]) + e_idx) * bar_width
            pos = index + offset - (len(models) * len(error_rates[::1]) - 1) * bar_width / 2

            # ç»˜åˆ¶æ¡å½¢ - è°ƒæ•´é€æ˜åº¦ä»¥å¢å¼ºå¯è§æ€§
            bars = ax.bar(pos, values, bar_width * 0.95,
                          color=colors[m_idx % len(colors)],
                          # color='white',
                          alpha=0.7 + 0.3 * e_idx / len(error_rates[::1]),
                          hatch=hatches[e_idx % len(hatches)],
                          # edgecolor=colors[m_idx % len(colors)],
                          # edgecolor='black',
                          label=f"{model.replace('_', ' ').title()} ({int(er * 100)}%)" if e_idx == 0 else "")
            for bar in bars:
                original_edge_color = bar.get_edgecolor()
                bar.set_edgecolor(original_edge_color)  # eg: æ¨¡å‹è‰²
                bar.set_linewidth(0.01)
                bar.set_path_effects([
                    path_effects.withStroke(linewidth=3.5, foreground='black')  # ğŸ‘ˆ å¤–æè¾¹é»‘è‰²
                ])

            # ä¸ºæ‰€æœ‰æ¡å½¢æ·»åŠ æ•°å­—æ ‡ç­¾
            for i, v in enumerate(values):
                # æ ¹æ®å€¼çš„å¤§å°è°ƒæ•´æ ‡ç­¾ä½ç½®å’Œé¢œè‰²
                if v > 0.15:  # æ›´å®½æ¾çš„é˜ˆå€¼ï¼Œæ˜¾ç¤ºæ›´å¤šæ ‡ç­¾
                    text_color = 'black' if v > 0.3 else 'black'
                    ax.text(pos[i], v + 0.02, f"{v:.2f}", ha='center', va='bottom',
                            fontsize=7, rotation=90, color=text_color, fontweight='bold')

    # è®¾ç½®å›¾è¡¨å±æ€§ - å¢å¼ºæ ‡é¢˜å’Œæ ‡ç­¾
    ax.set_xlabel('Action Type', fontsize=12, fontweight='bold')
    ax.set_ylabel('Proportion', fontsize=12, fontweight='bold')
    ax.set_title('Action Distribution by Model and Error Rate', fontsize=14, fontweight='bold')
    ax.set_xticks(index)
    ax.set_xticklabels(action_names, fontsize=10, fontweight='bold')

    # è·å–æ•°æ®æœ€å¤§å€¼ï¼Œè®¾ç½®åˆé€‚çš„yè½´èŒƒå›´
    data_max = 0
    for model_dist in action_dist.values():
        for er_dist in model_dist.values():
            current_max = max(er_dist.values())
            if current_max > data_max:
                data_max = current_max

    # è®¾ç½®yè½´ä¸Šé™ï¼Œç¡®ä¿æ‰€æœ‰æ ‡ç­¾éƒ½å¯è§
    if data_max < 0.95:
        y_max = min(1.0, data_max * 1.15)  # å¢åŠ æ›´å¤šç©ºé—´
    else:
        y_max = 1.05

    ax.set_ylim(0, y_max)

    # æ·»åŠ ç½‘æ ¼çº¿ä»¥æé«˜å¯è¯»æ€§
    ax.grid(True, linestyle='--', alpha=0.3)

    # æ·»åŠ æ¨¡å‹å›¾ä¾‹ - æ”¹è¿›å¸ƒå±€å’Œå¯è§æ€§
    handles, labels = ax.get_legend_handles_labels()
    l1 = ax.legend(handles, labels, loc='upper center', fontsize=9,
                   ncol=len(models), bbox_to_anchor=(0.5, -0.12), framealpha=0.8)

    # æ·»åŠ é”™è¯¯ç‡å›¾ä¾‹ - ä½¿ç”¨æ›´æ˜æ˜¾çš„æ ‡è®°
    error_patches = []
    for e_idx, er in enumerate(error_rates[::1]):
        # patch = mpatches.Patch(color='white', hatch=hatches[e_idx % len(hatches)],
        #                        label=f"{int(er * 100)}%", alpha=0.7)
        patch = mpatches.Patch(facecolor='white', hatch=hatches[e_idx % len(hatches)], edgecolor='gray', label=f"{int(er * 100)}%")

        error_patches.append(patch)

    l2 = ax.legend(handles=error_patches, loc='upper right', fontsize=9,
                   title="Error Rate", title_fontsize=10, framealpha=0.8)
    ax.add_artist(l1)
    plt.tight_layout(rect=[0, 0.03, 1, 1])  # [left, bottom, right, top]

    # plt.tight_layout()  # å¢åŠ è¾¹è·ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ å¯è§
    # è·å–æœ€å·¦è¾¹å’Œæœ€å³è¾¹çš„æ¡å½¢ä½ç½®
    total_bars = len(models) * len(error_rates)
    bar_span = total_bars * bar_width
    start = index[0] - bar_span / 2
    end = index[-1] + bar_span / 2 + bar_width

    # è®¾ç½® x è½´èŒƒå›´ï¼Œç¨å¾®ç•™å‡ºä¸€ç‚¹è¾¹è·
    ax.set_xlim(start, end)

    return fig, ax


def plot_performance_comparison(results, tolerances, models, error_rates, task_type, enhanced=True):
    """ä½¿ç”¨åˆ†ç»„æ¡å½¢å›¾ç»˜åˆ¶å¤šé”™è¯¯ç‡ç­–ç•¥æ€§èƒ½å¯¹æ¯”å›¾"""
    fig, ax = plt.subplots(figsize=(8, 5))

    # è®¾ç½®æ¡å½¢å›¾å‚æ•°
    bar_width = 0.08  # æ¡å½¢å®½åº¦
    opacity = 0.8  # æ¡å½¢é€æ˜åº¦

    # ä½¿ç”¨å¯¹æ¯”åº¦æ›´é«˜çš„é¢œè‰²
    if enhanced:
        model_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # æ¨¡å‹é¢œè‰²
    else:
        model_colors = plt.cm.tab10(np.linspace(0, 1, len(models)))

    # æ€§èƒ½æŒ‡æ ‡æ ‡ç­¾
    metric_label = 'Accuracy' if task_type == 'classification' else 'RÂ² Score'

    # ç­–ç•¥åç§°
    strategy_names = {
        'do_nothing': 'Do Nothing',
        'delete_all': 'Delete All',
        'repair_all': 'Repair All',
        'rl_optimal': 'RL Optimal'
    }

    # è®¾ç½®xè½´ä½ç½®
    index = np.arange(len(error_rates))  # æ¯ä¸ªé”™è¯¯ç‡ä¸€ä¸ªä½ç½®

    # ä¸»è¦å…³æ³¨çš„ç­–ç•¥
    highlighted_strategies = ['rl_optimal', 'repair_all', 'delete_all','do_nothing']

    # ä¸ºæ¯ä¸ªæ¨¡å‹ç»˜åˆ¶æ¡å½¢å’ŒæŠ˜çº¿
    for m_idx, model in enumerate(models):
        model_color = model_colors[m_idx % len(model_colors)]

        # æå–RLç­–ç•¥çš„æ€§èƒ½æ•°æ®ç”¨äºæŠ˜çº¿
        rl_values = [results[model][er]['rl_optimal'] for er in error_rates]

        # ç»˜åˆ¶æ¯ç§ç­–ç•¥çš„æ¡å½¢
        for s_idx, strategy in enumerate(highlighted_strategies):
            perf_values = [results[model][er][strategy] for er in error_rates]

            # è®¡ç®—æ¡å½¢ä½ç½®
            offset = (m_idx * len(highlighted_strategies) + s_idx) * bar_width
            positions = index + offset - (len(models) * len(highlighted_strategies) - 1) * bar_width / 2

            # è®¾ç½®æ¡å½¢æ ·å¼
            if strategy == 'rl_optimal':
                color = model_color
                hatch = ''
                alpha = 0.9
                edge_color = 'black'
                line_width = 1
                zorder = 10
            elif strategy == 'repair_all':
                color = 'white'
                hatch = '///'
                alpha = 0.7
                edge_color = model_color
                line_width = 1
                zorder = 5
            elif strategy == 'delete_all':
                color = 'white'
                hatch = 'xxx'
                alpha = 0.7
                edge_color = model_color
                line_width = 1
                zorder = 5
            else:
                color = 'white'
                hatch = '...'
                alpha = 0.7
                edge_color = model_color
                line_width = 1
                zorder = 5

            # ç»˜åˆ¶æ¡å½¢
            label = f"{model.replace('_', ' ').title()} - {strategy_names[strategy]}" if s_idx == 0 else None
            bars = ax.bar(
                positions,
                perf_values,
                bar_width * 0.9,
                alpha=alpha,
                color=color,
                hatch=hatch,
                edgecolor=edge_color,
                linewidth=line_width,
                label=label,
                zorder=zorder
            )

            # ä¸ºæ¡å½¢æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, v in enumerate(perf_values):
                # è®¾ç½®æ ‡ç­¾æ˜¾ç¤ºé˜ˆå€¼
                if v > 0.3:  # æ ¹æ®æ•°æ®è°ƒæ•´
                    ax.text(
                        positions[i],
                        v + 0.01,
                        f"{v:.2f}",
                        ha='center',
                        va='bottom',
                        fontsize=7,
                        color='black',
                        fontweight='bold' if strategy == 'rl_optimal' else 'normal',
                        rotation=90
                    )

        # æ·»åŠ è¶‹åŠ¿çº¿ - åªä¸ºRLç­–ç•¥æ·»åŠ 
        if len(error_rates) > 2:  # åªæœ‰å½“ç‚¹è¶³å¤Ÿå¤šæ—¶æ‰æ·»åŠ è¶‹åŠ¿çº¿
            trend_positions = index + (m_idx * len(highlighted_strategies)) * bar_width
            ax.plot(
                trend_positions,
                rl_values,
                color=model_color,
                linestyle='-',
                alpha=0.5,
                linewidth=1.5,
                zorder=15
            )

    # æ ‡æ³¨å®¹å¿åº¦é˜ˆå€¼ç‚¹
    for m_idx, model in enumerate(models):
        # æ‰¾åˆ°å®¹å¿åº¦ä¸‹é™åˆ°0.8çš„ç‚¹
        threshold = 0.8
        tolerance_array = np.array(tolerances[model])
        threshold_idx = np.abs(tolerance_array - threshold).argmin()
        threshold_er = error_rates[threshold_idx]
        threshold_perf = results[model][threshold_er]['rl_optimal']

        # æ‰¾åˆ°å¯¹åº”çš„xè½´ä½ç½®
        er_idx = error_rates.index(threshold_er)
        bar_offset = (m_idx * len(highlighted_strategies)) * bar_width
        x_pos = index[er_idx] + bar_offset - (len(models) * len(highlighted_strategies) - 1) * bar_width / 2

        # æ ‡æ³¨é˜ˆå€¼ç‚¹
        ax.scatter(
            [x_pos],
            [threshold_perf + 0.05],
            s=80,
            marker='v',
            facecolors=model_colors[m_idx % len(model_colors)],
            edgecolors='black',
            linewidth=1.5,
            zorder=20
        )
        ax.text(
            x_pos,
            threshold_perf + 0.06,
            f"T={threshold:.1f}",
            color=model_colors[m_idx % len(model_colors)],
            ha='center',
            fontsize=8,
            fontweight='bold'
        )

    # è®¾ç½®å›¾è¡¨å±æ€§
    ax.set_xlabel('Error Rate', fontsize=12, fontweight='bold')
    ax.set_ylabel(metric_label, fontsize=12, fontweight='bold')
    ax.set_title('Strategy Performance by Model and Error Rate', fontsize=14, fontweight='bold')

    # è®¾ç½®xè½´åˆ»åº¦ä½ç½®å’Œæ ‡ç­¾
    ax.set_xticks(index)
    ax.set_xticklabels([f"{er:.1f}" for er in error_rates], fontsize=10)

    # è®¡ç®—åˆé€‚çš„yè½´èŒƒå›´
    all_values = []
    for model in results:
        for er in results[model]:
            all_values.extend(results[model][er].values())

    y_min = max(0, min(all_values) - 0.05)
    y_max = min(1.0, max(all_values) + 0.15)  # å¢åŠ è¶³å¤Ÿç©ºé—´ç”¨äºæ ‡ç­¾
    ax.set_ylim(y_min, y_max)

    # æ·»åŠ ç½‘æ ¼çº¿
    ax.grid(True, linestyle='--', alpha=0.3, axis='y')
    ax.set_axisbelow(True)  # ç½‘æ ¼çº¿ç½®äºå›¾å½¢å…ƒç´ ä¹‹ä¸‹

    # è®¾ç½®åˆ»åº¦æ ‡ç­¾å­—ä½“
    ax.tick_params(axis='both', which='major', labelsize=10)

    # åˆ›å»ºå›¾ä¾‹
    handles, labels = ax.get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    legend = ax.legend(
        by_label.values(),
        by_label.keys(),
        loc='upper center',
        bbox_to_anchor=(0.5, -0.12),
        ncol=len(models),
        fontsize=9,
        framealpha=0.8
    )

    # æ·»åŠ ç­–ç•¥å›¾ä¾‹
    rl_patch = mpatches.Patch(color='gray', label='RL Optimal')
    repair_patch = mpatches.Patch(facecolor='white', hatch='///', edgecolor='gray', label='Repair All')
    delete_patch = mpatches.Patch(facecolor='white', hatch='xxx', edgecolor='gray', label='Delete All')
    nothing_patch = mpatches.Patch(facecolor='white', hatch='...', edgecolor='gray', label='DoNothing')
    strategy_legend = ax.legend(
        handles=[rl_patch, repair_patch,delete_patch,nothing_patch],
        loc='upper right',
        title='Strategies',
        fontsize=9,
        framealpha=0.8,
        title_fontsize=10
    )

    # ç¡®ä¿ä¸¤ä¸ªå›¾ä¾‹éƒ½æ˜¾ç¤º
    ax.add_artist(legend)
    # è°ƒæ•´ x è½´èŒƒå›´ä»¥å‡å°‘å·¦å³ç©ºéš™
    total_groups = len(models) * len(highlighted_strategies)
    total_bar_span = total_groups * bar_width
    left_bound = index[0] - total_bar_span / 2
    right_bound = index[-1] + total_bar_span / 2 + bar_width

    # ç•™å‡ºä¸€ç‚¹è¾¹è·
    ax.set_xlim(left_bound - 0.05, right_bound + 0.05)

    plt.tight_layout(rect=[0, 0.03, 1, 1])  # [left, bottom, right, top]

    return fig, ax


# 10. ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾å‡½æ•°
# def plot_performance_comparison(results, tolerances, models, error_rates, task_type, enhanced=True):
#     """ç»˜åˆ¶å¤šé”™è¯¯ç‡ç­–ç•¥æ€§èƒ½å¯¹æ¯”å›¾"""
#     fig, ax = plt.subplots(figsize=(7, 4.5))
#
#     # ä¸åŒç­–ç•¥çš„çº¿å‹
#     strategies = ['do_nothing', 'delete_all', 'repair_all', 'rl_optimal']
#     strategy_names = ['Do Nothing', 'Delete All', 'Repair All', 'RL Optimal']
#     line_styles = [':', '--', '-.', '-']
#     marker_styles = ['o', 's', '^', 'D']
#
#     # ä½¿ç”¨å¯¹æ¯”åº¦æ›´é«˜çš„é¢œè‰²
#     if enhanced:
#         colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']  # æ›´é²œæ˜çš„é¢œè‰²
#     else:
#         colors = plt.cm.tab10(np.linspace(0, 1, len(models)))
#
#     # æ€§èƒ½æŒ‡æ ‡æ ‡ç­¾
#     metric_label = 'Accuracy' if task_type == 'classification' else 'RÂ² Score'
#
#     # ç»˜åˆ¶æ€§èƒ½æŠ˜çº¿å›¾
#     for m_idx, model in enumerate(models):
#         for s_idx, strategy in enumerate(strategies):
#             # æ”¶é›†æ•°æ®ç‚¹
#             perf_values = [results[model][er][strategy] for er in error_rates]
#
#             # è®¾ç½®çº¿æ¡æ ·å¼
#             line_style = line_styles[s_idx]
#             marker = marker_styles[s_idx]
#             color = colors[m_idx % len(colors)]
#
#             # æ ¹æ®ç­–ç•¥é‡è¦æ€§è°ƒæ•´çº¿æ¡æ ·å¼
#             if strategy in ['rl_optimal', 'repair_all']:
#                 label = f"{model.replace('_', ' ').title()} - {strategy_names[s_idx]}" if m_idx == 0 else None
#                 # æ›´æ˜æ˜¾çš„çº¿æ¡
#                 lw = 2.0 if strategy == 'rl_optimal' else 1.5
#                 alpha = 1.0
#                 zorder = 10
#             else:
#                 label = f"{strategy_names[s_idx]}" if m_idx == 0 else None
#                 # æ›´ç»†çš„çº¿æ¡
#                 lw = 1.0
#                 alpha = 0.6
#                 zorder = 5
#
#             # ç»˜åˆ¶æŠ˜çº¿ - å¢å¼ºçº¿æ¡å¯è§æ€§
#             line = ax.plot(error_rates, perf_values, marker=marker, linestyle=line_style,
#                            color=color, linewidth=lw, markersize=5, label=label, alpha=alpha, zorder=zorder)
#
#             # åœ¨ç»ˆç‚¹ä¸ºRLç­–ç•¥æ·»åŠ æ ‡ç­¾ï¼Œå¢åŠ æ–‡æœ¬å¯è§æ€§
#             if strategy == 'rl_optimal':
#                 ax.text(error_rates[-1] + 0.02, perf_values[-1],
#                         f"{model.replace('_', ' ').title()}", color=color,
#                         fontsize=9, fontweight='bold', ha='left', va='center')
#
#     # æ ‡æ³¨å…³é”®å®¹å¿åº¦é˜ˆå€¼ç‚¹ - å¢å¼ºå¯è§æ€§
#     for m_idx, model in enumerate(models):
#         # æ‰¾åˆ°å®¹å¿åº¦ä¸‹é™åˆ°0.8çš„ç‚¹
#         threshold = 0.8
#         tolerance_array = np.array(tolerances[model])
#         # æ‰¾åˆ°æœ€æ¥è¿‘é˜ˆå€¼çš„é”™è¯¯ç‡ä½ç½®
#         threshold_idx = np.abs(tolerance_array - threshold).argmin()
#         threshold_er = error_rates[threshold_idx]
#         threshold_perf = results[model][threshold_er]['rl_optimal']
#
#         # æ ‡æ³¨é˜ˆå€¼ç‚¹ - ä½¿ç”¨æ›´å¤§æ›´æ˜æ˜¾çš„æ ‡è®°
#         ax.scatter([threshold_er], [threshold_perf], s=100,
#                    facecolors='none', edgecolors=colors[m_idx % len(colors)],
#                    linewidth=2.0, zorder=15)
#         ax.text(threshold_er, threshold_perf - 0.04,
#                 f"T={threshold:.1f}", color=colors[m_idx % len(colors)],
#                 ha='center', fontsize=9, fontweight='bold')
#
#     # è®¾ç½®å›¾è¡¨å±æ€§ - å¢å¼ºæ ‡é¢˜å’Œæ ‡ç­¾
#     ax.set_xlabel('Error Rate', fontsize=12, fontweight='bold')
#     ax.set_ylabel(metric_label, fontsize=12, fontweight='bold')
#     ax.set_title('Strategy Performance vs Error Rate', fontsize=14, fontweight='bold')
#
#     # è®¡ç®—åˆé€‚çš„yè½´èŒƒå›´
#     all_values = []
#     for model in results:
#         for er in results[model]:
#             all_values.extend(results[model][er].values())
#
#     y_min = max(0, min(all_values) - 0.05)
#     y_max = min(1.0, max(all_values) + 0.05)
#
#     # å¢åŠ é¢å¤–ç©ºé—´ï¼Œç¡®ä¿æ‰€æœ‰æ ‡ç­¾å¯è§
#     ax.set_ylim(y_min, y_max + 0.05)
#     ax.set_xlim(min(error_rates) - 0.02, max(error_rates) + 0.07)  # å¢åŠ å³ä¾§ç©ºé—´
#
#     # æ·»åŠ ç½‘æ ¼çº¿ - å¢å¼ºå¯¹æ¯”åº¦
#     ax.grid(True, linestyle='--', alpha=0.4, zorder=0)
#
#     # è®¾ç½®åˆ»åº¦æ ‡ç­¾å­—ä½“
#     ax.tick_params(axis='both', which='major', labelsize=10)
#
#     # åˆ›å»ºåˆ†ç»„å›¾ä¾‹ - å¢å¼ºå¯è§æ€§
#     # 1. ç­–ç•¥å›¾ä¾‹
#     strategy_lines = []
#     for i, name in enumerate(strategy_names):
#         if name in ['RL Optimal', 'Repair All']:
#             line = plt.Line2D([0], [0], color='black', linestyle=line_styles[i],
#                               marker=marker_styles[i], markersize=5,
#                               linewidth=2.0 if name == 'RL Optimal' else 1.5,
#                               label=name)
#         else:
#             line = plt.Line2D([0], [0], color='black', linestyle=line_styles[i],
#                               marker=marker_styles[i], markersize=5,
#                               linewidth=1.0, alpha=0.6, label=name)
#         strategy_lines.append(line)
#
#     # å°†ç­–ç•¥å›¾ä¾‹æ”¾åœ¨å·¦ä¸‹è§’ï¼Œå¢åŠ é€æ˜åº¦
#     l1 = ax.legend(handles=strategy_lines, loc='lower left',
#                    title='Strategies', fontsize=9, framealpha=0.8,
#                    title_fontsize=10)
#
#     # 2. æ¨¡å‹å›¾ä¾‹ (æ”¾åœ¨å³ä¸Šè§’)
#     model_patches = [mpatches.Patch(color=colors[i % len(colors)],
#                                     label=model.replace('_', ' ').title(),
#                                     alpha=0.9)
#                      for i, model in enumerate(models)]
#
#     # å¢åŠ æ¨¡å‹å›¾ä¾‹çš„å¯è§æ€§
#     l2 = ax.legend(handles=model_patches, loc='upper right',
#                    title='Models', fontsize=9, framealpha=0.8,
#                    title_fontsize=10)
#
#     # ç¡®ä¿ä¸¤ä¸ªå›¾ä¾‹éƒ½æ˜¾ç¤º
#     ax.add_artist(l1)
#
#     plt.tight_layout(pad=1.1)  # å¢åŠ è¾¹è·ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ å¯è§
#
#     return fig, ax


# 11. ç»“æœåˆ†æå‡½æ•°
def analyze_results(results, action_dist, tolerances, models, error_rates, task_type):
    """åˆ†æå®éªŒç»“æœå¹¶æ‰“å°å…³é”®é‡åŒ–æ•°æ®"""
    print("\n===== å…³é”®é‡åŒ–ç»“æœ =====")

    # 1. ä½é”™è¯¯ç‡åœºæ™¯ä¸‹çš„åŠ¨ä½œåˆ†å¸ƒ
    low_error = min(error_rates)
    print(f"\n1. ä½é”™è¯¯ç‡({low_error:.1f})ä¸‹çš„åŠ¨ä½œåˆ†å¸ƒ:")
    for model in models:
        no_action = action_dist[model][low_error]['no_action'] * 100
        repair = action_dist[model][low_error]['repair'] * 100
        delete = action_dist[model][low_error]['delete'] * 100
        print(f"   {model}: ä¸ä½œä¸º={no_action:.1f}%, ä¿®å¤={repair:.1f}%, åˆ é™¤={delete:.1f}%")

    # 2. é«˜é”™è¯¯ç‡åœºæ™¯ä¸‹çš„åŠ¨ä½œåˆ†å¸ƒ
    high_error = max(error_rates)
    print(f"\n2. é«˜é”™è¯¯ç‡({high_error:.1f})ä¸‹çš„åŠ¨ä½œåˆ†å¸ƒ:")
    for model in models:
        no_action = action_dist[model][high_error]['no_action'] * 100
        repair = action_dist[model][high_error]['repair'] * 100
        delete = action_dist[model][high_error]['delete'] * 100
        print(f"   {model}: ä¸ä½œä¸º={no_action:.1f}%, ä¿®å¤={repair:.1f}%, åˆ é™¤={delete:.1f}%")

    # 3. æ¨¡å‹å®¹å¿åº¦æ¯”è¾ƒ
    print("\n3. ä¸åŒæ¨¡å‹çš„å¹³å‡å®¹å¿åº¦:")
    for model in models:
        avg_tolerance = np.mean(tolerances[model]) * 100
        print(f"   {model}: å¹³å‡å®¹å¿åº¦={avg_tolerance:.1f}%")

    # 4. RLç­–ç•¥ä¸å…¨éƒ¨ä¿®å¤çš„æ€§èƒ½æ¯”è¾ƒ
    print("\n4. RLç­–ç•¥ä¸å…¨éƒ¨ä¿®å¤çš„æ€§èƒ½æ¯”è¾ƒ:")
    for model in models:
        avg_rl = np.mean([results[model][er]['rl_optimal'] for er in error_rates]) * 100
        avg_repair = np.mean([results[model][er]['repair_all'] for er in error_rates]) * 100
        ratio = avg_rl / avg_repair * 100
        print(f"   {model}: RL={avg_rl:.1f}%, å…¨éƒ¨ä¿®å¤={avg_repair:.1f}%, æ¯”ä¾‹={ratio:.1f}%")

    # 5. åŠ¨ä½œæˆæœ¬æ•ˆç›Šåˆ†æ
    print("\n5. åŠ¨ä½œæˆæœ¬æ•ˆç›Šåˆ†æ:")
    for model in models:
        # è®¡ç®—å¹³å‡ä¿®å¤æˆæœ¬èŠ‚çœ (ä¸å…¨éƒ¨ä¿®å¤ç›¸æ¯”)
        avg_repair_saved = np.mean([1 - action_dist[model][er]['repair'] for er in error_rates]) * 100
        # è®¡ç®—å¹³å‡åˆ é™¤æˆæœ¬èŠ‚çœ (ä¸å…¨éƒ¨åˆ é™¤ç›¸æ¯”)
        avg_delete_saved = np.mean([1 - action_dist[model][er]['delete'] for er in error_rates]) * 100
        # å¹³å‡æ€§èƒ½æ¯”ä¾‹
        avg_perf_ratio = np.mean([results[model][er]['rl_optimal'] / results[model][er]['repair_all']
                                  for er in error_rates]) * 100
        print(f"   {model}: å‡å°‘ä¿®å¤={avg_repair_saved:.1f}%, å‡å°‘åˆ é™¤={avg_delete_saved:.1f}%, "
              f"æ€§èƒ½ä¿æŒ={avg_perf_ratio:.1f}%")

    # 6. é”™è¯¯ç‡é˜ˆå€¼åˆ†æ
    print("\n6. é”™è¯¯ç‡é˜ˆå€¼åˆ†æ:")
    for model in models:
        # æ‰¾åˆ°æ€§èƒ½ä¸‹é™è¶…è¿‡10%çš„é”™è¯¯ç‡é˜ˆå€¼
        baseline_perf = results[model][min(error_rates)]['repair_all']
        threshold_er = max(error_rates)
        for er in error_rates:
            current_perf = results[model][er]['rl_optimal']
            perf_drop = (baseline_perf - current_perf) / baseline_perf
            if perf_drop > 0.1:  # æ€§èƒ½ä¸‹é™è¶…è¿‡10%
                threshold_er = er
                break
        print(f"   {model}: æ€§èƒ½æ˜¾è‘—ä¸‹é™é˜ˆå€¼={threshold_er:.1f}")

    # 7. ä¸åŒæ¨¡å‹å¯¹ä¸åŒé”™è¯¯ç±»å‹çš„æ•æ„Ÿåº¦åˆ†æ
    print("\n7. æ¨¡å‹æ•æ„Ÿåº¦åˆ†æ:")
    sensitivity = {}
    for model in models:
        # é”™è¯¯ç‡å¢åŠ æ—¶ï¼ŒRLä¿®å¤æ“ä½œå¢åŠ çš„é€Ÿç‡
        low_repair = action_dist[model][min(error_rates)]['repair']
        high_repair = action_dist[model][max(error_rates)]['repair']
        repair_sensitivity = (high_repair - low_repair) / (max(error_rates) - min(error_rates))

        # é”™è¯¯ç‡å¢åŠ æ—¶ï¼Œæ€§èƒ½ä¸‹é™çš„é€Ÿç‡
        low_perf = results[model][min(error_rates)]['rl_optimal']
        high_perf = results[model][max(error_rates)]['rl_optimal']
        perf_sensitivity = (low_perf - high_perf) / (max(error_rates) - min(error_rates))

        sensitivity[model] = {
            'repair_sensitivity': repair_sensitivity,
            'perf_sensitivity': perf_sensitivity
        }

        print(f"   {model}: ä¿®å¤æ•æ„Ÿåº¦={repair_sensitivity:.2f}, æ€§èƒ½æ•æ„Ÿåº¦={perf_sensitivity:.2f}")

    # 8. æ¨¡å‹å®¹å¿åº¦æ’å
    model_tolerance_avg = {model: np.mean(tolerances[model]) for model in models}
    sorted_models = sorted(model_tolerance_avg.items(), key=lambda x: x[1], reverse=True)

    print("\n8. æ¨¡å‹å®¹å¿åº¦æ’å:")
    for rank, (model, tolerance) in enumerate(sorted_models, 1):
        print(f"   ç¬¬{rank}å: {model} (å®¹å¿åº¦={tolerance:.2f})")

    return sensitivity


# 12. å®Œæ•´å®éªŒè¿è¡Œå‡½æ•°
# 12. å®Œæ•´å®éªŒè¿è¡Œå‡½æ•°
# def run_tolerance_experiment(error_rates=[0.1, 0.2, 0.3, 0.4, 0.5],
#                              models=['random_forest', 'svm', 'logistic_regression'],
#                              task_type='classification',
#                              n_samples=1000,
#                              n_features=5,
#                              missing_ratio=0.33,
#                              outlier_ratio=0.33,
#                              noise_ratio=0.34,
#                              enhanced_visuals=True):
#     """
#     è¿è¡Œå¤šé”™è¯¯ç‡å¤šæ¨¡å‹å®¹å¿åº¦å®éªŒå¹¶ç»˜åˆ¶ç»“æœå›¾
#
#     å‚æ•°:
#         error_rates: è¦æµ‹è¯•çš„é”™è¯¯ç‡åˆ—è¡¨
#         models: è¦æµ‹è¯•çš„æœºå™¨å­¦ä¹ æ¨¡å‹åˆ—è¡¨
#         task_type: 'classification' æˆ– 'regression'
#         n_samples: æ•°æ®é›†æ ·æœ¬æ•°
#         n_features: æ•°æ®é›†ç‰¹å¾æ•°
#         missing_ratio: ç¼ºå¤±å€¼é”™è¯¯çš„æ¯”ä¾‹
#         outlier_ratio: å¼‚å¸¸å€¼é”™è¯¯çš„æ¯”ä¾‹
#         noise_ratio: å™ªå£°é”™è¯¯çš„æ¯”ä¾‹
#         enhanced_visuals: æ˜¯å¦ä½¿ç”¨å¢å¼ºçš„å¯è§†åŒ–æ•ˆæœ
#
#     è¿”å›:
#         fig1, fig2, results_data: ä¸¤ä¸ªå›¾å½¢å¯¹è±¡å’Œä¸€ä¸ªåŒ…å«è¯¦ç»†ç»“æœçš„å­—å…¸
#     """
#     # åˆå§‹åŒ–ç»“æœæ•°æ®ç»“æ„
#     results, action_dist, tolerances = setup_experiment(
#         error_rates, models, task_type, n_samples, n_features,
#         missing_ratio, outlier_ratio, noise_ratio)
#
#     # å¯¹æ¯ä¸ªé”™è¯¯ç‡è¿è¡Œå®éªŒ
#     for error_rate in error_rates:
#         results, action_dist, tolerances = run_single_error_rate_experiment(
#             error_rate, models, task_type, n_samples, n_features,
#             missing_ratio, outlier_ratio, noise_ratio,
#             results, action_dist, tolerances)
#
#     # ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒå›¾
#     fig1, ax1 = plot_action_distribution(
#         action_dist, models, error_rates, enhanced=enhanced_visuals)
#
#     # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾
#     fig2, ax2 = plot_performance_comparison(
#         results, tolerances, models, error_rates, task_type, enhanced=enhanced_visuals)
#
#     # åˆ†æå¹¶è¾“å‡ºç»“æœ
#     sensitivity = analyze_results(
#         results, action_dist, tolerances, models, error_rates, task_type)
#
#     # è¿”å›å›¾å½¢å’Œå®Œæ•´ç»“æœæ•°æ®
#     results_data = {
#         'results': results,
#         'action_dist': action_dist,
#         'tolerances': tolerances,
#         'sensitivity': sensitivity
#     }
#
#     return fig1, fig2, results_data
#
def run_tolerance_experiment(error_rates=[0.1, 0.2, 0.3, 0.4, 0.5],
                             models=['random_forest', 'svm', 'logistic_regression'],
                             task_type='classification',
                             n_samples=1000,
                             n_features=5,
                             missing_ratio=0.33,
                             outlier_ratio=0.33,
                             noise_ratio=0.34,
                             enhanced_visuals=True):
    """
    è¿è¡Œå¤šé”™è¯¯ç‡å¤šæ¨¡å‹å®¹å¿åº¦å®éªŒå¹¶ç»˜åˆ¶ç»“æœå›¾
    """
    # åˆå§‹åŒ–ç»“æœæ•°æ®ç»“æ„
    results, action_dist, tolerances = setup_experiment(
        error_rates, models, task_type, n_samples, n_features,
        missing_ratio, outlier_ratio, noise_ratio)

    # 1. åœ¨å®éªŒå¼€å§‹æ—¶ç”Ÿæˆè®­ç»ƒå’Œæµ‹è¯•çš„å¹²å‡€æ•°æ®
    print("ç”Ÿæˆå¹²å‡€çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®...")
    train_clean_df = generate_clean_data(task_type=task_type, n_samples=n_samples, n_features=n_features)
    # è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆåªéœ€è®¡ç®—ä¸€æ¬¡ï¼‰
    feature_importance = calculate_feature_importance(train_clean_df, task_type)
    print(f"ç‰¹å¾é‡è¦æ€§: {feature_importance}")

    # ç”Ÿæˆé¢å¤–çš„æµ‹è¯•æ•°æ®ï¼ˆç¡®ä¿ä¸è®­ç»ƒæ•°æ®ä¸åŒï¼‰
    test_clean_df = generate_clean_data(task_type=task_type, n_samples=n_samples, n_features=n_features)

    # å¯¹æ¯ä¸ªé”™è¯¯ç‡è¿è¡Œå®éªŒ
    for error_rate in error_rates:
        print(f"Running experiment with error rate: {error_rate}")

        # è®¡ç®—æ¯ç§é”™è¯¯ç±»å‹çš„é”™è¯¯ç‡
        missing_err_rate = error_rate * missing_ratio
        outlier_err_rate = error_rate * outlier_ratio
        noise_err_rate = error_rate * noise_ratio

        # è®­ç»ƒé˜¶æ®µï¼šä½¿ç”¨è®­ç»ƒæ•°æ®æ³¨å…¥é”™è¯¯
        train_injector = ErrorInjector(train_clean_df.copy())
        train_injector.inject_missing_values(error_rate=missing_err_rate, feature_importance=feature_importance)
        train_injector.inject_outliers(error_rate=outlier_err_rate, feature_importance=feature_importance)
        train_injector.inject_noise(error_rate=noise_err_rate, feature_importance=feature_importance)
        train_df_with_errors = train_injector.df

        # å‡†å¤‡è®­ç»ƒæ•°æ®åˆ†å‰²
        X_train_full = train_clean_df.drop('target', axis=1)
        y_train_full = train_clean_df['target']
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)

        # å¯¹æ¯ä¸ªæ¨¡å‹è¿è¡Œå®éªŒ
        for model_name in models:
            print(f"  Testing model: {model_name}")
            # åˆå§‹åŒ–MLæ¨¡å‹
            ml_model = initialize_ml_model(task_type, model_name)

            # åˆ›å»ºè®­ç»ƒç¯å¢ƒå’Œè¯„ä¼°å™¨
            train_env = DataCleaningEnv(train_df_with_errors.copy(), ml_model, train_injector.error_locations,
                                        task_type=task_type, model_type=model_name)

            # è®­ç»ƒRLä»£ç†
            agent, _ = train_rl_agent(train_env, train_injector.error_locations)

            # æµ‹è¯•é˜¶æ®µï¼šä½¿ç”¨æµ‹è¯•æ•°æ®æ³¨å…¥ç›¸åŒç¨‹åº¦çš„é”™è¯¯
            test_injector = ErrorInjector(test_clean_df.copy())
            test_injector.inject_missing_values(error_rate=missing_err_rate, feature_importance=feature_importance)
            test_injector.inject_outliers(error_rate=outlier_err_rate, feature_importance=feature_importance)
            test_injector.inject_noise(error_rate=noise_err_rate, feature_importance=feature_importance)
            test_df_with_errors = test_injector.df

            # å‡†å¤‡æµ‹è¯•è¯„ä¼°å™¨å’Œç¯å¢ƒ
            test_evaluator, test_env = setup_test_environment(
                test_clean_df, test_df_with_errors, test_injector, ml_model,
                task_type, model_name)

            # è¯„ä¼°ä¸åŒç­–ç•¥
            strat_perf = evaluate_strategies(
                task_type, test_df_with_errors,
                test_injector.error_locations, test_evaluator, test_env, agent)

            # è®°å½•ç»“æœ
            update_results(results, action_dist, tolerances, model_name, error_rate,
                           task_type, strat_perf, test_env, test_injector, agent)

    # ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒå›¾
    fig1, ax1 = plot_action_distribution(
        action_dist, models, error_rates, enhanced=enhanced_visuals)

    # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾
    fig2, ax2 = plot_performance_comparison(
        results, tolerances, models, error_rates, task_type, enhanced=enhanced_visuals)

    # åˆ†æå¹¶è¾“å‡ºç»“æœ
    sensitivity = analyze_results(
        results, action_dist, tolerances, models, error_rates, task_type)

    # è¾“å‡ºå®Œæ•´çš„ç»“æœæ•°æ®
    print("\n===== å®Œæ•´å®éªŒç»“æœ =====")
    print("\nAction Distribution:")
    import json
    print(json.dumps(action_dist, indent=2, default=str))
    print("\nPerformance Results:")
    print(json.dumps(results, indent=2, default=str))

    # è¿”å›å›¾å½¢å’Œå®Œæ•´ç»“æœæ•°æ®
    results_data = {
        'results': results,
        'action_dist': action_dist,
        'tolerances': tolerances,
        'sensitivity': sensitivity
    }

    return fig1, fig2, results_data


# ç¤ºä¾‹è°ƒç”¨
if __name__ == "__main__":
    # è¿è¡Œå®éªŒå¹¶ç”Ÿæˆå›¾è¡¨
    fig1, fig2, results_data = run_tolerance_experiment(
        error_rates=[0.1, 0.3, 0.5, 0.7, 0.9],
        # error_rates=[0.5],
        models=['random_forest', 'svm', 'logistic_regression'],
        task_type='classification',
        n_samples=1000,  # å‡å°‘æ ·æœ¬é‡ä»¥åŠ å¿«å®éªŒé€Ÿåº¦
        n_features=5,
        enhanced_visuals=True  # ä½¿ç”¨å¢å¼ºçš„å¯è§†åŒ–æ•ˆæœ
    )

    # ä¿å­˜å›¾è¡¨ä¸ºé«˜è´¨é‡PDF
    fig1.savefig('action_distribution_enhanced.pdf', bbox_inches='tight', dpi=600)
    fig2.savefig('performance_comparison_enhanced.pdf', bbox_inches='tight', dpi=600)

    # å±•ç¤ºå›¾è¡¨
    plt.figure(fig1.number)
    plt.show()
    plt.figure(fig2.number)
    plt.show()

    # è®¿é—®è¯¦ç»†ç»“æœç¤ºä¾‹
    rf_tolerance = results_data['tolerances']['random_forest']
    svm_actions = results_data['action_dist']['svm']
    lr_performance = results_data['results']['logistic_regression']

    # print(f"\nRandom Forest å®¹å¿åº¦: {rf_tolerance}")
    # print(f"SVM åœ¨é”™è¯¯ç‡ 0.7 çš„åŠ¨ä½œåˆ†å¸ƒ: {svm_actions[0.7]}")
    # print(f"Logistic Regression åœ¨é”™è¯¯ç‡ 0.9 çš„æ€§èƒ½: {lr_performance[0.9]}")
